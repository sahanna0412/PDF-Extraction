# -*- coding: utf-8 -*-
"""pdf extractor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1owMg5x9KLja_lsVkJfD8VfRHxZV0pPaD
"""

pip install pypdf2

pip install pdfplumber

pip install pytesseract

pip install pandas

pip install pytesseract

pip install numpy

pip install faiss-cpu

import os
import gc
import pdfplumber
import pandas as pd
import numpy as np
import faiss
from tqdm import tqdm
from PIL import Image
from sentence_transformers import SentenceTransformer
from typing import Generator, Tuple

pip install pdf2image

pip install tabula-py

pip install opencv-python

pip install matplotlib

import PyPDF2
import pdf2image
import pytesseract
import cv2
import numpy as np
import tabula
from PIL import Image, ImageDraw
import matplotlib.pyplot as plt

class AdvancedPDFExtractor:
    def __init__(self):
        self.text_content = []
        self.tables = []
        self.images = []
        self.layout = []

    def extract_all(self, pdf_path):
        """Main extraction function"""
        # Extract basic text and layout
        self._extract_text_and_layout(pdf_path)

        # Process images and OCR
        self._extract_images_and_ocr(pdf_path)

        # Extract tables
        self._extract_tables(pdf_path)

        return {
            'text': self.text_content,
            'tables': self.tables,
            'images': self.images,
            'layout': self.layout
        }

def _extract_text_and_layout(self, pdf_path):
        """Extract text and basic layout information"""
        with open(pdf_path, 'rb') as file:
            reader = PyPDF2.PdfReader(file)
            for page_num, page in enumerate(reader.pages):
                text = page.extract_text()
                self.text_content.append({
                    'page': page_num + 1,
                    'content': text,
                    'type': 'text'
                })

from PyPDF2 import PdfReader

def extract_layout_elements(pdf_path):
    """Extract rectangles and other layout elements from a PDF"""
    rectangles = []

    with open(pdf_path, 'rb') as file:
        reader = PdfReader(file)

        for page_num, page in enumerate(reader.pages):
            if '/Annots' in page:
                for annot in page['/Annots']:
                    annot_obj = annot.get_object()
                    if annot_obj['/Subtype'] == '/Square':  # Check if it's a rectangle
                        rectangles.append({
                            'page': page_num + 1,
                            'type': 'rectangle',
                            'coordinates': annot_obj['/Rect']
                        })

    return rectangles

!pip install pypdf2 pdf2image pytesseract tabula-py opencv-python-headless pandas matplotlib

!sudo apt install tesseract-ocr
!pip install pytesseract

!sudo apt install default-jre

from google.colab import files
uploaded = files.upload()

pdf_path = list(uploaded.keys())[0]

# Required installations:
# !pip install pypdf2 pdf2image pytesseract tabula-py opencv-python-headless pandas matplotlib
# !sudo apt install tesseract-ocr default-jre

import PyPDF2
import pdf2image
import pytesseract
import cv2
import numpy as np
import tabula
from PIL import Image, ImageDraw
import matplotlib.pyplot as plt
from google.colab import files

class AdvancedPDFExtractor:
    def __init__(self):
        self.text_content = []
        self.tables = []
        self.images = []
        self.layout = []

    def extract_all(self, pdf_path):
        """Main extraction function"""
        # Extract basic text and layout
        self._extract_text_and_layout(pdf_path)

        # Process images and OCR
        self._extract_images_and_ocr(pdf_path)

        # Extract tables
        self._extract_tables(pdf_path)

        return {
            'text': self.text_content,
            'tables': self.tables,
            'images': self.images,
            'layout': self.layout
        }

    def _extract_text_and_layout(self, pdf_path):
        """Extract text and basic layout information"""
        with open(pdf_path, 'rb') as file:
            reader = PyPDF2.PdfReader(file)
            for page_num, page in enumerate(reader.pages):
                text = page.extract_text()
                self.text_content.append({
                    'page': page_num + 1,
                    'content': text,
                    'type': 'text'
                })

                # Extract basic layout elements (example: rectangles)
                if '/Annots' in page:
                    for annot in page['/Annots']:
                        annot_obj = annot.get_object()
                        if annot_obj['/Subtype'] == '/Square':
                            self.layout.append({
                                'page': page_num + 1,
                                'type': 'rectangle',
                                'coordinates': annot_obj['/Rect']
                            })

    def _extract_images_and_ocr(self, pdf_path):
        """Extract images and perform OCR"""
        images = pdf2image.convert_from_path('/content/Minimalist Grey and White Professional Resume (8).pdf')
        for page_num, img in enumerate(images):
            # Save original image
            img_path = f"page_{page_num+1}_original.png"
            img.save(img_path, 'PNG')

            # Perform OCR
            ocr_text = pytesseract.image_to_string(img)

            # Detect tables in image (simple version)
            table_coords = self._detect_tables_in_image(img)

            self.images.append({
                'page': page_num + 1,
                'original_image': img_path,
                'ocr_text': ocr_text,
                'tables': table_coords
            })

            # Create annotated view
            annotated_img = self._create_annotated_view(img, table_coords)
            annotated_path = f"page_{page_num+1}_annotated.png"
            annotated_img.save(annotated_path)

    def _detect_tables_in_image(self, img):
        """Simple table detection using OpenCV"""
        # Convert to grayscale and detect edges
        img_np = np.array(img)
        gray = cv2.cvtColor(img_np, cv2.COLOR_BGR2GRAY)
        edges = cv2.Canny(gray, 50, 150)

        # Detect lines
        lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=50,
                               minLineLength=50, maxLineGap=10)

        # Simple table detection (count horizontal and vertical lines)
        table_coords = []
        if lines is not None:
            # This is a simplified example - real table detection would be more complex
            table_coords.append({
                'x1': 100, 'y1': 100,  # Example coordinates
                'x2': 500, 'y2': 400,
                'confidence': 0.8
            })
        return table_coords

    def _create_annotated_view(self, img, table_coords):
        """Draw annotations on the image"""
        draw = ImageDraw.Draw(img)
        for table in table_coords:
            draw.rectangle(
                [table['x1'], table['y1'], table['x2'], table['y2']],
                outline='red',
                width=3
            )
        return img

    def _extract_tables(self, pdf_path):
        """Extract tables using tabula"""
        tables = tabula.read_pdf(pdf_path, pages='all', multiple_tables=True)
        for idx, table in enumerate(tables):
            self.tables.append({
                'table_number': idx + 1,
                'content': table,
                'html': table.to_html(),
                'type': 'table'
            })

    def visualize_page(self, page_number):
        """Visualize page layout with annotations"""
        img = Image.open(f"page_{page_number}_annotated.png")
        plt.figure(figsize=(20, 20))
        plt.imshow(img)
        plt.axis('off')
        plt.show()

# Upload PDF file
uploaded = files.upload()
pdf_path = list(uploaded.keys())[0]

# Initialize and run the extractor
extractor = AdvancedPDFExtractor()
results = extractor.extract_all(pdf_path)

# Display results
print("Extracted Text Content:")
for text in results['text']:
    print(f"Page {text['page']}:")
    print(text['content'][:200] + "...")  # Show first 200 characters

print("\nExtracted Tables:")
for table in results['tables']:
    print(f"Table {table['table_number']}:")
    print(table['content'].head())  # Show first few rows

print("\nVisualizing Page 1 Layout:")
extractor.visualize_page(1)

!apt-get install poppler-utils

def _extract_images_and_ocr(self, pdf_path):
        """Extract images and perform OCR"""
        images = pdf2image.convert_from_path('/content/Neuron Model.pdf') # Use the pdf_path variable
        # ... rest of the function ...

!apt-get install poppler-utils # Install poppler-utils to provide pdfinfo

# Required installations:
# !pip install pypdf2 pdf2image pytesseract tabula-py opencv-python-headless pandas matplotlib
# !sudo apt install tesseract-ocr default-jre

import PyPDF2
import pdf2image
import pytesseract
import cv2
import numpy as np
import tabula
from PIL import Image, ImageDraw
import matplotlib.pyplot as plt
from google.colab import files

# ... (rest of your code)

class AdvancedPDFExtractor:  # Assuming this is where the class definition starts
    # ... (Other methods: __init__, extract_all, _extract_text_and_layout, etc.)

    def _extract_images_and_ocr(self, pdf_path):  # Corrected indentation
        """Extract images and perform OCR"""
        images = pdf2image.convert_from_path(pdf_path) # Use the provided pdf_path
        # ... rest of the function ...

# ... (rest of your code)

class AdvancedPDFExtractor:
    def __init__(self, pdf_path):
        self.pdf_path = pdf_path

    def extract_all(self):
        """Extract text, images, and tables from the PDF."""
        text_and_layout = self._extract_text_and_layout()
        images_and_ocr = self._extract_images_and_ocr()
        tables = self._extract_tables()

        return {
            "text_and_layout": text_and_layout,
            "images_and_ocr": images_and_ocr,
            "tables": tables
        }

    def _extract_text_and_layout(self):
        """Extract text and layout information using PyPDF2."""
        text = ""
        with open(self.pdf_path, "rb") as file:
            reader = PyPDF2.PdfReader(file)
            for page in reader.pages:
                text += page.extract_text()
        return text

    def _extract_images_and_ocr(self):
        """Extract images and perform OCR using pytesseract."""
        images = pdf2image.convert_from_path(self.pdf_path)
        ocr_results = []
        for image in images:
            ocr_text = pytesseract.image_to_string(image)
            ocr_results.append(ocr_text)
        return ocr_results

    def _extract_tables(self):
        """Extract tables using tabula-py."""
        tables = tabula.read_pdf(self.pdf_path, pages="all", multiple_tables=True)
        return tables

    def visualize_images(self):
        """Visualize extracted images."""
        images = pdf2image.convert_from_path(self.pdf_path)
        for i, image in enumerate(images):
            plt.figure(figsize=(10, 10))
            plt.imshow(image)
            plt.title(f"Page {i+1}")
            plt.axis('off')
            plt.show()

# Example usage
if __name__ == "__main__":
    # Upload a PDF file in Google Colab
    uploaded = files.upload()
    pdf_path = list(uploaded.keys())[0]

    # Initialize the extractor
    extractor = AdvancedPDFExtractor(pdf_path)

    # Extract all data
    extracted_data = extractor.extract_all()

    # Print extracted text
    print("Extracted Text and Layout:")
    print(extracted_data["text_and_layout"])

    # Print OCR results
    print("\nOCR Results:")
    for i, ocr_text in enumerate(extracted_data["images_and_ocr"]):
        print(f"Page {i+1} OCR:\n{ocr_text}\n")

    # Print extracted tables
    print("\nExtracted Tables:")
    for i, table in enumerate(extracted_data["tables"]):
        print(f"Table {i+1}:\n{table}\n")

    # Visualize extracted images
    extractor.visualize_images()